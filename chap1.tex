\chapter{Introduction}

\begin{quotation}
\textit{Let me tell you, thats what makes us human---coming up with a million \mbox{different} ideas.}
\newline{}
\newline{}
 ---Ushikawa, Wind-Up Bird Chronicle
\end{quotation}

\section{Overview}

Plasticity, the ability to change, is a key feature of the brain's function. While much of what is needed to instruct development is encoded in an organism's genome, success is more likely when the individual can bring information from past experiences to bear on its response to a new stimulus, i.e. when it can learn. 

\section{Early thoughts on plasticity}
The origins of a theoretical consideration of neural plasticity can be traced back to William James, who chose the term to refer to the changes that give rise to habitual behaviors (\cite{James1910, Berlucchi2009}). While he postulated about the mechanisms of plasticity, he admitted that the experimental techniques and concepts had not matured enough to bring a full understanding to light, and deferred the task of elucidating the details to future generations of scientists.

As James predicted, the following decades saw enormous progress in our understanding of the molecular details of plasticity mechanisms. Italian psychologists Eugenio Tanzi and Ernesto Lugaro and Spanish anatomist Santiago Ram\a`on y Cajal began to develop the idea that formation of new connections between neurons was the physiological instatiation of learning in the brain (\cite{Berlucchi2009}). In his 1949 book ``Organization of Behavior," Donald Hebb clarified the idea of changing synpatic weights as a basis for learning. He described his model as follows:

\begin{quotation}
Let us assume that the persistence or repetition of a reverberatory activity (or ``trace") tends to induce lasting cellular changes that add to its stability. [...] When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A's efficiency, as one of the cells firing B, is increased.
\end{quotation}

Hebb's rule, as this theory came to be known, charted new territory in the understanding of brain plasticity and thus, brain function. It brought the field closer to the goal of a specific theory for how activity in a neural circuit is translated into instructions for modifying that circuit to incorporate new information.

\section{From theory to physiology}

Proof that such a principle actually operated in the brain began to accumulate in 1968 when Timothy Bliss and Terje L\o mo discovered experimental evidence for Hebbian plasticity in rabbit dentate granule cells (\cite{Bliss1973}). High-frequency stimulation of of the perforant path inputs onto granule cells in the dentate gyrus led to a long-lasting potentiation of those inputs. This stimulation To this implementation of Hebbian learning, they gave the name ``long-term potentiation" or LTP.

With empirical evidence for the link between input-output correlation and increased synaptic weight in hand, it was reasonable to assume there might be a mechanism that operated to decrease synaptic weights between pairs of neuron's whose activity was uncorrelated. Long-term depression, as it came to be known, 

Networks whose plasticity is governed solely by Hebbian plasticity are prone to unstable behavior. If a given synapse participates in driving the post-synaptic target to fire, its weight will be increased, causing it to be more likely to activate the post-synaptic neuron, increasing its weight, and so on. Conversely, a synapse that is only weakly correlated will fall into a negative feedback loop and its weight will be reduced to zero. Not only is this an unusable learning process from a theoretical standpoint, it does not agree with experimental evidence that shows the distribution of synaptic weights on a neuron to be roughly normally distributed with a slight positive skew rather than the ``all-or-none" distibution predicted by purely Hebbian learning mechanisms (\cite{Turrigiano1998}). Although Hebbian learning is a powerful learning rule that appeared to actually operate in the brain, its instability in isolation led scientists to the hypothesis that there must be additional mechanisms at play, ones that could ensure network stability in the brain.

\section{Homeostatic plasticity: change to stay the same}

That key missing component was a way to ensure activity \textit{homeostasis}, the maintenence of activity (usually represented by neuronal firing rate) within a biologically acceptable range of values. An extraordinary number of factors determine the overall electrical activity of a neuron, and the brain seems to have evolved ways to modulate many of them to achieve homeostasis. The sodium, potassium, and calcium channels that determine a neuron's intrinsic excitability could be modulated (\cite{Franklin1992}). The system could attenuate the degree of plasticity for strong synapses, preventing run-away synaptic strengthening (\cite{VanRossum2000}). Another option is to increase or decrease the strengths of all synaptic inputs to the neuron to counter-act deviations from the desired activity range. By multiplicitavely scaling all synapses, the cell can change its overall activity level without sacrificing the information contained in the synaptic weights.

In 2006, Stellwagen and Malenka discovered that this form of homeostatic plasticity, called synaptic scaling, depends on the presence of the protein TNF-\textalpha{}. Importantly, the absence of TNF-\textalpha{} had no effect on LTP and LTD, showing that the mechanisms for Hebbian and homeostatic plasticity do not significantly overlap and allowing the future studies to consider two processes with some degree of isolation (\cite{Stellwagen2006}). In addition, the development of mouse line lacking TNF-\textalpha{} gave researchers the ability to study the role of homeostatic plasticity in a wide range of \textit{in vivo} preparations. This tool was put to use to examine the 

\section{Moving forward}

With the theoretical foundations in place and the physiological mechanisms outlined, a major challenge is to understand how these plasticity rules defined at the level of pairs of neurons or small neural assemblies operate and co-operate to affect larger scale network dynamics.

% This instability results from the coupling of changes in synapticchanges in synaptic weights onto a neuron are driven by correlations between synpatic input and spiking output, so that 

% And when once the possibility of some kind of mechanical interpretation is established, Mechanical Science, in her present mood, will not hesitate to set her brand of ownership upon the matter, feeling sure that it is only a question of time when the exact mechanical explanation of the case shall be found out.

% All this is vague to the last degree, and amounts to little more than saying that a new path may be formed by the sort of chances that in nervous material are likely to occur. But, vague as it is, it is really the last word of our wisdom in the matter.


